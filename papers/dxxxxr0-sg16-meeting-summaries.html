<!doctype html public "-//W3C//DTD HTML 4.01//EN" "http://www.w3.org/TR/html4/strict.dtd">
<meta http-equiv="Content-Type" content="text/html;charset=UTF-8">

<head>
<title>SG16: Unicode meeting summaries 2020-09-09 through 2020-09-23</title>
</head>

<style type="text/css">

table#header th,
table#header td
{
    text-align: left;
}

tt {
    font-family: monospace;
}

/* Thanks to Elias Kosunen for the following CSS suggestions! */

* {
    font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, "Helvetica Neue", Arial, "Noto Sans", sans-serif, "Apple Color Emoji", "Segoe UI Emoji", "Segoe UI Symbol", "Noto Color Emoji";
    line-height: 125%;
}

html, body {
    background-color: #eee;
}

h1, h2, h3, h4, h5, p, span, li, dt, dd {
    color: #333;
}

p, li {
    line-height: 140%;
}

body {
    padding: 1em;
    max-width: 1600px;
}

p, li {
    -moz-osx-font-smoothing: grayscale;
    -webkit-font-smoothing: antialiased !important;
    -moz-font-smoothing: antialiased !important;
    text-rendering: optimizelegibility !important;
    letter-spacing: .01em;
}

h1, h2, h3 {
    margin-bottom: 1em;
    letter-spacing: .03em;
}

blockquote.quote
{
    margin-left: 0em;
    border-style: solid;
    background-color: lemonchiffon;
    color: #000000;
    border: 1px solid black;
}

</style>

<body>

<table id="header">
  <tr>
    <th>Document Number:</th>
    <td>DXXXXR0 <em>Draft</em></td>
  </tr>
  <tr>
    <th>Date:</th>
    <td>2020-09-27</td>
  </tr>
  <tr>
    <th>Audience:</th>
    <td>SG16</td>
  </tr>
  <tr>
    <th>Reply-to:</th>
    <td>Tom Honermann &lt;tom@honermann.net&gt;</td>
  </tr>
</table>


<h1>SG16: Unicode meeting summaries 2020-09-09 through 2020-09-23</h1>

<p>
Summaries of SG16 meetings are maintained at
<a href="https://github.com/sg16-unicode/sg16-meetings">
https://github.com/sg16-unicode/sg16-meetings</a>.  This paper contains a
snapshot of select meeting summaries from that repository.
</p>

<ul>
  <li><a href="#2020_09_09">
      September 9th, 2020</a></li>
  <li><a href="#2020_09_23">
      September 23rd, 2020</a></li>
</ul>

<p>
Previously published SG16 meeting summary papers:
<ul>
  <li><a href="https://wg21.link/p1080">P1080: SG16: Unicode meeting summaries 2018/03/28 - 2018/04/25</a></li>
  <li><a href="https://wg21.link/p1137">P1137: SG16: Unicode meeting summaries 2018/05/16 - 2018/06/20</a></li>
  <li><a href="https://wg21.link/p1237">P1237: SG16: Unicode meeting summaries 2018/07/11 - 2018/10/03</a></li>
  <li><a href="https://wg21.link/p1422">P1422: SG16: Unicode meeting summaries 2018/10/17 - 2019/01/09</a></li>
  <li><a href="https://wg21.link/p1666">P1666: SG16: Unicode meeting summaries 2019/01/23 - 2019/05/22</a></li>
  <li><a href="https://wg21.link/p1896">P1896: SG16: Unicode meeting summaries 2019/06/12 - 2019/09/25</a></li>
  <li><a href="https://wg21.link/p2009">P2009: SG16: Unicode meeting summaries 2019-10-09 through 2019-12-11</a></li>
  <li><a href="https://wg21.link/p2179">P2179: SG16: Unicode meeting summaries 2020-01-08 through 2020-05-27</a></li>
  <li><a href="https://wg21.link/p2217">P2217: SG16: Unicode meeting summaries 2020-06-10 through 2020-08-26</a></li>
</ul>
</p>


<h1 id="2020_09_09">September 9th, 2020</h1>

<h2>Draft agenda:</h2>

<ul>
  <li><a href="https://wg21.link/p2178r1">P2178R1: Misc lexing and string handling improvements</a>
    <ul>
      <li>Discuss proposal 1: Mandating support for UTF-8 encoded source files in phase 1</li>
    </ul>
  </li>
  <li><a href="https://isocpp.org/files/papers/P2194R0.pdf">P2194R0: The character set of C++ source code is Unicode</a></li>
</ul>

<h2>Attendees:</h2>

<ul>
  <li>Corentin Jabot</li>
  <li>Hubert Tong</li>
  <li>Jens Maurer</li>
  <li>Mark Zeren</li>
  <li>Peter Bindels</li>
  <li>Peter Brett</li>
  <li>Steve Downey</li>
  <li>Tom Honermann</li>
  <li>Victor Zverovich</li>
  <li>Zach Laine</li>
</ul>

<h2>Meeting summary:</h2>

<ul>
  <li>Administrative updates:
    <ul>
      <li>Tom provided an update on the WG14 timeline for C2X.
        <ul>
          <li>WG14 sent out notification that C2X must be published by
              August 31st, 2023.</li>
          <li>That means C2X must be feature complete by August of 2022.</li>
          <li>Any proposals that we want to get in to C for compatibility
              reasons needs to be done or (close to done) by
              August of 2022.</li>
        </ul>
      </li>
      <li>PBindels noted that timeline aligns well with C++23.</li>
    </ul>
  </li>
  <li><a href="https://wg21.link/p2178r1">P2178R1: Misc lexing and string handling improvements</a>
    <ul>
      <li>Proposal 1: Mandating support for UTF-8 encoded source files in
          phase 1
        <ul>
          <li>Corentin provided an introduction:
            <ul>
              <li>The intent of the proposal is to specify that the set of
                  implementation-defined source file encodings shall include
                  UTF-8.</li>
              <li>This reflects standard practice amongst the major
                  implementations.</li>
              <li>The meachanism used to specify that the source encoding is
                  UTF-8 remains implementation-defined.</li>
              <li>Implementations may use any mechanism desired to determine
                  which encoding to use.</li>
              <li>Quoting Richard Smith: "If we want C++ to be portable, there
                  must be a portable source file encoding".</li>
              <li>This proposal is orthogonal to any hypothetical proposal to
                  allow differently encoded source files in the same
                  translation unit.</li>
              <li>Per Unicode guidelines, a UTF-8 BOM would be handled as
                  whitespace.</li>
            </ul>
          </li>
          <li>PBrett asked if Corentin is open to follow up papers that tackle
              additional issues.</li>
          <li>Corentin responded that Tom has work in-progress that is
              orthogonal to this paper.</li>
          <li>PBrett urged adoption; this suffices to compile a source package
              on any platform.</li>
          <li>Tom stated that, in practice, there are at least four sets of
              source files involved when compiling any non-trivial project.
              Those are,
              1) the source files for the project,
              2) the C standard headers,
              3) the C++ standard headers, and
              4) the platform header files (POSIX, Win32 SDK, etc...).
              The question is how these disparate projects adopt UTF-8
              incrementally.</li>
          <li>Corentin replied that z/OS is an exception that would require
              support for a mix of UTF-8 and EBCDIC source files; on other
              platforms, system headers are limited to ASCII in practice.
              Vcpkg currently compiles all packages as UTF-8.</li>
          <li>Jens stated that standard headers are below the concern of the
              standard; they are effectively magic and implementations can
              provide whatever mechanisms they desire to make them work.</li>
          <li>Jens added that it is always ok to restrict oneself to the basic
              source character set and only use UTF-8 when targeting a UTF-8
              supporting compiler.</li>
          <li>Hubert stated that the standard has separate wording for headers
              vs source files; the latter are also an abstraction in the
              standard and we can specify that physical source file characters
              are composed from code units, but that still leaves open the
              question of what the container is.  On many platforms a file is a
              sequence of bytes, but for some implementations, a source file may
              be a sequential data set of fixed length records.</li>
          <li>Hubert added that, with regard to specifying use of a UTF-8 BOM to
              detect the encoding, some implementations have other means for
              encoding detection; for example, z/OS allows specifying an
              encoding via filesystem metadata.</li>
          <li>Tom revisited PBrett's scenario of a portable source package on
              any platform, noted that there are additional source file sets
              involved if there are third party package dependencies, and stated
              a desire for a UTF-8 solution to be optimized for deployment and
              migration across the ecosystem.</li>
          <li>Corentin acknowledged that desire but asserted that is not a goal
              of the current proposal.</li>
          <li>PBrett asked the attendant core experts how to word this proposal
              given that the standard doesn't require actual source files.</li>
          <li>Hubert responded that the standard discusses source files but
              leaves their structure undefined; we can specify a specific form
              of source file as, e.g., a sequence of UTF-8 code units.</li>
          <li>Corentin agreed and stated that direction matches the intent; a
              network stream of UTF-8 code units should be acceptable as a
              source file.</li>
          <li>Jens added that the standard is hazy about what a source file is;
              it is an abstraction and must not be required to be something that
              can, for example, be opened by <tt>fopen()</tt>; compilers can be
              written in any language and therefore can't rely on the C++ notion
              of files.  Specifying a UTF-8 encoding will necessarily require
              punching through the existing abstraction.</li>
          <li>Zach expanded on Tom's concern and noted that, for existing
              projects, the compiler already knows how to perform encoding
              conversions; if we have to alter the specification for translation
              phases, that seems ok.</li>
          <li>Zach noted that addressing the simple use case where all source
              files are known to be UTF-8 is important.</li>
          <li>Mark stated that C++20 modules potentially provides additional
              separation between source files.</li>
          <li>Corentin agreed and emphasized Mark's point.</li>
          <li>Tom responded that exploiting that potential requires the ability
              to specify encoding options on a per-TU basis, but that is ok;
              that is an issue for build systems to address.</li>
          <li>Hubert noted that the wording for headers may be quite different
              than for source files.</li>
          <li>Corentin asked if translation phases 1 through 3 are processed
              independently for each header.</li>
          <li>Hubert responded that he didn't think we specify that headers
              (as opposed to source files) are read in this manner.</li>
          <li>PBrett noted that this will require digging a tunnel through the
              implementation-defined behavior currently present in translation
              phase 1.</li>
          <li>Corentin agreed, but noted that there is only so much we can
              specify happen prior to translation phase 1.</li>
          <li>Hubert elaborated on prior comments regarding different wording
              for headers vs source files; the form of the <tt>#include</tt>
              directive written with a quoted name is specified to look for a
              source file and then, if one isn't found, to retry as if the
              directive were written with a name in angle brackets; headers can
              be resolved in this form.</li>
          <li>Jens expressed a belief that standard library headers are headers
              and other things are source files.</li>
          <li>Hubert agreed, but noted that a source file can interpose on a
              header.</li>
          <li>Tom switched the focus to handling of BOMs and presented a hostile
              example of not specifying behavior when a BOM is present; one
              implementation could choose to require a BOM, another could choose
              not to permit one, and another could choose to allow them
              optionally and use their presence to inform encoding.</li>
          <li>Corentin replied that, in Unicode, BOMs are not whitespace and
              should be ignored; they can be used to detect the encoding, but
              not to reject a code unit stream assumed to be UTF-8.</li>
          <li>Hubert stated that wording is definitely required to express
              that.</li>
          <li>PBrett stated that a BOM can only appear at the start of a source
              file; a BOM code unit sequence at the start of a string literal is
              not a BOM.</li>
          <li>Hubert responded that there may not be agreement on that; there
              could be special cases for raw-string literals.</li>
          <li>Corentin asserted that a BOM is a non-breaking white space;
              U+FEFF is "ZERO WIDTH NO-BREAK SPACE".</li>
          <li>PBindels provided a linke to
              <a href="https://www.unicode.org/faq/utf_bom.html#bom6">https://www.unicode.org/faq/utf_bom.html#bom6</a>
              which states:
              <div style="padding: .5em; background: #E9FBE9">
              Q: What should I do with U+FEFF in the middle of a file?
                <div style="padding: .5em; background: #E9FBE9">
                A: In the absence of a protocol supporting its use as a BOM and
                when not at the beginning of a text stream, U+FEFF should
                normally not occur. For backwards compatibility it should be
                treated as ZERO WIDTH NON-BREAKING SPACE (ZWNBSP), and is then
                part of the content of the file or string. The use of U+2060
                WORD JOINER is strongly preferred over ZWNBSP for expressing
                word joining semantics since it cannot be confused with a BOM.
                When designing a markup language or data protocol, the use of
                U+FEFF can be restricted to that of Byte Order Mark. In that
                case, any U+FEFF occurring in the middle of a file can be
                treated as an unsupported character.
              </div>
            </div>
          </li>
          <li>PBindels noted that the old use of U+FEFF as a zero-width
              non-breaking space character was deprecated in Unicode 3.</li>
          <li>Tom replied that U+FEFF is only white space when present
              somewhere other than the beginning of the input; it should be
              ignored when present as the first code unit sequence.</li>
          <li>Hubert stated that there is a distinction from a source code
              column perspective, but that there is nothing in C or C++ that
              requires a token to appear at the start of a line.</li>
          <li>Hubert clarified that there are cases in C++ where adding a
              space matters.</li>
          <li>PBrett suggested that handling of BOMs be a subject of further
              work.</li>
          <li>Tom explained that gcc and Visual C++ conflict with regard to
              handling of BOMs.  Gcc will ignore one when directed to compile
              as UTF-8, but will emit an error otherwise.  Visual C++ uses a
              BOM to inform encoding.</li>
          <li>Hubert raised a question regarding whether a BOM is or is not
              part of the source file content.</li>
          <li>Jens restated Hubert's question in more concrete terms by asking
              if a BOM is visible during translation phases 1 and 2.</li>
          <li>Corentin replied that standard practice is inconsistent because
              tools are not consistent; if we don't want to break existing
              tools then we can't require a BOM.</li>
          <li>Tom agreed and asserted that no one has suggested a BOM should
              be required.</li>
          <li>PBrett summarized recent discussion; there is implementation
              divergence regarding whether a BOM is honored as indicating an
              encoding vs being ignored.</li>
          <li>PBrett suggested a survey of existing tools is needed.</li>
          <li>Hubert noted that, with respect to Corentin's last statement;
              we haven't taken a position.  It is likely not controversial to
              ignore a BOM when processing as UTF-8; but we know we don't
              want to require a BOM.</li>
          <li>Hubert added that it sounds like gcc doesn't use a BOM for
              encoding detection; in which case the BOM is not a BOM.  It
              sounds like existing compilers effectively ignore it.</li>
          <li>Tom stated that he doesn't know of any experiments that can
              reveal whether a BOM is handled as white space or removed as
              file content.</li>
          <li>PBindels asked if that is observable.</li>
          <li>Hubert responded that it is via compiler diagnostics.</li>
          <li>Zach stated that he prefers the approach of a source annotation
              or command line option to select encoding as BOMs are kind of
              magical.</li>
          <li>Zach suggested tabling further discussion of BOM handling
              until/unless we have a separate proposal.</li>
          <li>Corentin observed that current web browsers will prioritize
              source encoding tags over a BOM.</li>
          <li>PBrett expressed support for not specifying any BOM behavior for
              an initial proposal.</li>
          <li>Hubert asserted that something must be specified regarding BOM
              allowance in order for wording to not otherwise reject source
              files with a BOM.</li>
          <li><b>Poll: All implementations should be required to provide an
              implementaion-defined mechanism to support the scenario in which
              all source files used within a translation unit are UTF-8 encoded
              whether or not they have a UTF-8 BOM</b>.
            <ul>
              <li><b>Attendees: 10</b></li>
              <li><b>No objection to unanimous consent.</b></li>
            </ul>
          </li>
          <li>Tom asked if we should poll whether files must consistently have
              a BOM.</li>
          <li>Zach asked if that isn't already covered by separate processing
              of translation phases 1 through 3.</li>
          <li>Jens replied that it is.</li>
          <li>Zach stated that we should not do that poll then.</li>
          <li>Tom agreed.</li>
          <li><b>Poll: It should be implementation-defined whether a UTF-8 BOM
              is used to inform the encoding of a source file.</b>
            <ul>
              <li>Mark clarified that voting in favor is a vote for
                  implementation divergence.</li>
              <li><b>Attendees: 10</b></li>
              <li>
                <table>
                  <tr>
                    <th style="text-align:right">SF</th>
                    <th style="text-align:right">F</th>
                    <th style="text-align:right">N</th>
                    <th style="text-align:right">A</th>
                    <th style="text-align:right">SA</th>
                  </tr>
                  <tr>
                    <th style="text-align:right">4</th>
                    <th style="text-align:right">3</th>
                    <th style="text-align:right">1</th>
                    <th style="text-align:right">2</th>
                    <th style="text-align:right">0</th>
                  </tr>
                </table>
              </li>
              <li><b>Consensus is in favor.</b></li>
              <li>A: I would prefer well-defined behavior over
                  implementation-defined behavior.</li>
              <li>Hubert responded that implementation-defined behavior is
                  needed for z/OS in order for filesystem based meta-data to be
                  consulted; requiring 100% conformance with a BOM would be
                  problematic.</li>
            </ul>
          </li>
          <li><b>Poll: The presence or absence of a BOM is a reasonable
              portable mechanism for detecting UTF-8 source file encoding.</b>
            <ul>
              <li><b>Attendees: 10</b></li>
              <li>
                <table>
                  <tr>
                    <th style="text-align:right">SF</th>
                    <th style="text-align:right">F</th>
                    <th style="text-align:right">N</th>
                    <th style="text-align:right">A</th>
                    <th style="text-align:right">SA</th>
                  </tr>
                  <tr>
                    <th style="text-align:right">0</th>
                    <th style="text-align:right">1</th>
                    <th style="text-align:right">0</th>
                    <th style="text-align:right">3</th>
                    <th style="text-align:right">6</th>
                  </tr>
                </table>
              </li>
              <li><b>No consensus; or rather, consensus is that a BOM is not a
                  reasonable portable mechanism for detection of source file
                  encoding.</b></li>
              <li>PBrett explained that his position is weakly held because
                  there may be obscure implementation circumstances where only
                  an unreasonable mechanism exists.</li>
              <li>Hubert noted that programmers can add a BOM themselves.</li>
              <li>F: BOMs are used within the Microsoft ecosystem to inform
                  encoding and appear to be useful there.</li>
              <li>Hubert responded that such a scenario is reasonable for
                  Windows, but that doesn't suffice to claim it as a reasonable
                  portable mechanism.</li>
              <li>Mark noted that the first poll taken leaves this option
                  available.</li>
              <li>Corentin stated that the source annotation approach is a
                  superior solution.</li>
            </ul>
          </li>
        </ul>
      </li>
    </ul>
  </li>
  <li>Tom stated that the next meeting will be in two weeks, on September 23rd,
      and will focus on
      <a href="https://isocpp.org/files/papers/P2194R0.pdf">P2194</a>.</li>
  <li>Tom asked Jens to confirm that he has a competing paper.</li>
  <li>Jens responded affirmatively, but that he is waiting for
      <a href="https://wg21.link/p2029">P2029</a> to land.</li>
  <li>Jens reminded the group that there is need to progress
      <a href="https://wg21.link/p1949">P1949</a>; it appears to be stuck in
      EWG.</li>
  <li>Tom asked Steve if
      <a href="https://wg21.link/p1949">P1949</a>
      was ready for another round in EWG.</li>
  <li>Steve confirmed that it is, has been submitted for the mailing, and that
      he will prepare slides.</li>
  <li>Tom promised to ping JF.</li>
  <li><em>[ Editor's note: Tom did so and JF put it on the EWG schedule for
      Thursday, September 24th. ]</em></li>
  <li>Hubert reminded the group that there will be a plenary in November and
      that papers made tentatively ready by EWG will require another meeting
      to be approved.</li>
</ul>


<h1 id="2020_09_23">September 23rd, 2020</h1>

<h2>Draft agenda:</h2>

<ul>
  <li><a href="https://wg21.link/p1949r6">P1949R6: C++ Identifier Syntax using Unicode Standard Annex 31</a>
    <ul>
      <li>Ensure we are collectively prepared for presentation to EWG on Thursday.</li>
    </ul>
  </li>
  <li><a href="https://isocpp.org/files/papers/P2194R0.pdf">P2194R0: The character set of C++ source code is Unicode</a></li>
  <li>Review
      <a href="https://github.com/tzlaine/text">Boost.Text</a>
      changes following initial Boost review.</li>
</ul>

<h2>Attendees:</h2>

<ul>
  <li>Corentin Jabot</li>
  <li>Hubert Tong</li>
  <li>Jens Maurer</li>
  <li>Mark Zeren</li>
  <li>Martinho Fernandes</li>
  <li>Peter Brett</li>
  <li>Steve Downey</li>
  <li>Tom Honermann</li>
  <li>Victor Zverovich</li>
  <li>Zach Laine</li>
</ul>

<h2>Meeting summary:</h2>

<ul>
  <li><a href="https://wg21.link/p1949r6">P1949R6: C++ Identifier Syntax using Unicode Standard Annex 31</a>
    <ul>
      <li>Tom explained that the goal of this review is to ensure we are
          collectively prepared for the presentation to EWG on Thursday.
          Specifically:
        <ul>
          <li>To perform a run-through of Steve's slides and provide
              feedback.</li>
          <li>To play devil's advocate in anticipation of questions or concerns
              that may be raised at the EWG telecon.</li>
        </ul>
      </li>
      <li>Steve presented:
        <ul>
          <li><em>[ Editor's note: Steve's draft slides are available in the
              SG16 mailing list archive at
              <a href="https://lists.isocpp.org/sg16/2020/09/1866.php">https://lists.isocpp.org/sg16/2020/09/1866.php</a>.
              ]</em></li>
          <li>The slides present a brief summary of the proposal, challenges
              with emoji support, script impact, uses of
              <a href="https://unicode.org/reports/tr31">UAX #31</a>
              by other languages, and wording overview.</li>
          <li>Summary slides present the identifier syntax, requirements for
              <a href="https://unicode.org/reports/tr15">NFC normalization</a>,
              and that this proposal addresses C++20 NB comment NL029.</li>
          <li>The status quo is that identifiers can be surprising as they may
              look like symbols or incorporate characters that look like
              operators.</li>
          <li>The proposed identifiers are closed over normalization and are
              guaranteed stable by the Unicode standard.</li>
          <li>The status quo for emoji support in identifiers is that it is
              accidental, incomplete, and broken.</li>
          <li>Emoji are not guaranteed stable by the Unicode standard.
              Supporting emoji could introduce instability to identifiers over
              time; what was once an identifier may cease to be one in the
              future.</li>
          <li>Some characters categorized as emoji are surprising; for example,
              <tt>#</tt>, <tt>*</tt>, and the decimal digits <tt>0</tt> through
              <tt>9</tt> are all categorized as emoji since they may begin an
              emoji keycap sequence.</li>
          <li>Supporting emoji would require being inventive; there is no
              standard for use of emojis in identifiers.</li>
          <li>Support for emoji in identifiers could be added later with an
              appropriate proposal.</li>
          <li>The proposal does not exclude any scripts.</li>
          <li>Some scripts, including English, contain words that are not valid
              as identifiers.  English examples include <tt>can't</tt>,
              <tt>won't</tt>, and <tt>mother-in-law</tt>.  Likewise, some
              scripts require use of invisible characters like ZWJ (U+200D) and
              ZWNJ (U+200C) to spell some words and, in some cases, these
              characters are all that differentiate some words.  For example,
              the Farsi words
              <tt>نامهای</tt> (U+0646 U+0627 U+0645 U+0647 U+0627 U+06CC) and
              <tt>نامه‌ای</tt> (U+0646 U+0627 U+0645 U+0647 U+200C U+0627 U+06CC)
              differ only by the presence of a ZWNJ.</li>
          <li>Other languages, including at least Java, Python, Erlang, Rust,
              and ECMAScript have adopted UAX #31.</li>
          <li>Wording has been provided by a CWG expert.</li>
        </ul>
      </li>
      <li>Jens suggested that the 'OTHER "WEIRD IDENTIFIER CODE POINTS"' slide
          be updated to make it clear that the content reflects the C++20
          status quo.</li>
      <li>Zach suggested being more specific about the end result of allowing
          unassigned code points in identifiers; that choice enabled some emoji
          to be incorporated in an unprincipled fashion.</li>
      <li>Jens suggested increasing the font size for examples.</li>
      <li>PBrett requested updates to slides with examples to make it clear
          whether they reflect the C++20 status quo or proposed behavior.</li>
      <li>Jens questioned the motivation behind some of the presented examples;
          if the challenge faced by supporting emoji is algorithmic complexity,
          then it would make sense to present the complicated examples
          first.</li>
      <li>Zach suggested that it might be productive to include the grapheme
          cluster rules on a slide.</li>
      <li>Steve responded that the paper includes a complicated regular
          expression copied from
          <a href="https://www.unicode.org/reports/tr51">UTS #51</a>
          that can be used to match a possible, but not necessarily valid,
          emoji sequence; that could be added.</li>
      <li>Tom commented on the "SOME SURPRISING THINGS ARE EMOJI" slide; that
          example demonstrates that lexing would be made more challenging
          because emoji sequences can begin with members of the basic source
          character set.</li>
      <li>Steve agreed and presented a related concern; whether <tt>1</tt>
          followed by U+20E3 (COMBINING ENCLOSING KEYCAP), a valid emoji,
          would be allowed to start an identifier.</li>
      <li>PBrett noted that a standard that addressed how to incorporate emoji
          support into identifiers would benefit other languages.</li>
      <li>Jens requested the use of lowercase letters in the examples of
          English words that can't be used as identifiers in order to maintain
          focus on the punctuation characters.</li>
      <li>Tom suggested that the "ZWJ AND ZWNJ" slide make it more clear what
          is being illustrated; that <tt>نامهای</tt> is a valid identifier,
          but that <tt>نامه‌ای</tt> is not because it includes a ZWNJ.</li>
      <li>Hubert suggested updating spacing to make the ZWNJ presence more
          clear.</li>
      <li>Hubert noted that UAX #31 doesn't prescribe handling of ZWJ and ZWNJ,
          but rather provides a recommendation; it would be disengenuous to
          claim disallowance of these characters based on UAX #31.</li>
      <li>Steve acknowledged and noted that script analysis could be performed,
          but that doing so would be difficult.</li>
      <li>Corentin asserted that we are not qualified to make decisions that
          affect, for example, Farsi; such decisions should be driven by domain
          experts.</li>
      <li>Martinho requested adding rationale for why ZWJ and ZWNJ characters
          should be rejected in identifiers.</li>
      <li>Hubert responded that the reason for rejection is that their presence
          may not affect presentation.</li>
      <li>Corentin noticed Rust listed on the "OTHER ADOPTERS" page and stated
          that Rust hasn't adopted UAX #31 yet.</li>
      <li>PBrett expressed a belief that Rust had adopted UAX #31.</li>
      <li>Martinho provided a link to the Rust tracking issue,
          <a href="https://github.com/rust-lang/rust/issues/55467">https://github.com/rust-lang/rust/issues/55467</a>,
          and explained that, though the issue is not yet resolved, the
          proposal has been accepted and is implemented in the development
          tree; there just hasn't been a new release of Rust that includes it
          yet.</li>
      <li>Tom suggested that C# could be added to the list of adopters.</li>
      <li>Corentin disagreed and noted that the C# specification is still based
          on category properties, not the XID properties.</li>
      <li>Tom opined that it sounds like C# was an early adopter of UAX #31 and
          still uses the older properties; C# presumably has identifier
          stability issues as a result.</li>
      <li>Corentin suggested that the wording slide isn't helpful and could be
          dropped.</li>
      <li>Jens requested that, if the wording slide is retained, that the text
          be left-align.</li>
      <li>Jens noted that there is a formal step that EWG affirm wording, but
          that it isn't necessary to dive into details.</li>
      <li>Jens recollected that, during the last EWG review, the major concerns
          were about emoji and script support.</li>
      <li>Tom and Steve both confirmed that recollection.</li>
      <li>Zach commented that the script restrictions involving Farsi was just
          an example; the point is that some scripts have similar limitations
          as English with respect to some words not being valid identifiers.
          Steve agreed and noted that some words in some scripts require white
          space.</li>
      <li>Jens added that we know of no script that is completely excluded.</li>
      <li>PBrett asked if a poll to forward the paper to CWG should be expected
          in the EWG telecon.</li>
      <li>Tom and Jens described the tentatively ready process adopted in
          Prague; that the paper can be made tentatively read at the next
          plenary, and then adopted at the following plenary.</li>
      <li>Tom asked if any other languages are known to support emoji in
          identifiers.</li>
      <li>Corentin replied that Swift does.</li>
      <li>Tom responded that Swift currently uses the same approach that C++20
          does, so Swift's emoji support is just as broken as that in
          C++20.</li>
      <li>Corentin added that Swift also allows some emoji as operators.</li>
      <li>Corentin opined that emoji are generally considered like symbols and
          therefore shouldn't appear in identifiers.</li>
      <li>Martinho noted that CSS allows just about any character in an
          identifier.</li>
      <li>Tom discussed an additional complication faced by supporting emoji;
          the text and emoji presentation styles.  Emoji characters have a
          default presentation style that can be changed by a presentation
          selector; the question is whether an emoji sequence with a
          presentation selector that matches the default presentation style
          and an emoji sequence without a presentation selector should be
          considered valid spellings of the same identifier.</li>
      <li>Tom noted that the slides don't present what would be required in
          order to support emoji well.</li>
      <li>Tom asked if there is a fast path option such that the complexity
          needed to support emoji is only paid if emoji are used.</li>
      <li>Corentin replied that lexing behavior would have to become EGC
          based.</li>
      <li>Tom asked how much of the Unicode property DB would be required for
          emoji support and noted that the emoji data text files are about
          67K.</li>
      <li>Corentin noted that other data may be required depending on design
          decisions.</li>
    </ul>
  </li>
  <li><a href="https://wg21.link/p2194r0">P2194R0: The character set of C++ source code is Unicode</a>
    <ul>
      <li>PBrett presented, assisted by Corentin.
        <ul>
          <li>This paper forked from proposal 9 of
              <a href="https://wg21.link/p2178r1">P2178R1: Misc lexing and string handling improvements</a>.</li>
          <li>SG16 has had several passionate discussions about this in the
              past.</li>
          <li>The ideas presented are Corentin's, PBrett provided the
              prose.</li>
          <li>Key points:
            <ul>
              <li>This is not a proposal to change the standard.</li>
              <li>This is not a proposal to change any implementations.</li>
              <li>This is about how we think about lexing and parsing.</li>
            </ul>
          </li>
          <li>C++20 is, perhaps accidentally, correct as is by requiring all
              source input characters to be representable by either basic
              source characters or Universal Character Names (UCNs).</li>
          <li>Taking a dependency on Unicode is reasonable.</li>
          <li>In C++20, translation phase 1 is effectively limited to Unicode
              scalar values by the requirement that translation phase 1
              produce only basic source characters and UCNs.</li>
          <li>Only UTF encodings produce scalar values without requiring a
              character set map.</li>
          <li><em>[ Editor's note: presentation was cut short at this point by
              discussion and time constraints. ]</em></li>
        </ul>
      </li>
      <li>Hubert asked why the paper contains proposed wording if it is not
          intended to change the standard.</li>
      <li>PBrett responded that the Proposed Wording section will be removed
          in the next revision and additional content added to clarify the
          difference between Unicode scalar value and character.</li>
      <li><em>[ Editor's note: the following discussion concerns the difference
          between a Unicode scalar value (a Unicode code point that is not a
          surrogate code point) and a Unicode assigned character (a Unicode
          code point that represents an abstract character). ]</em></li>
      <li>Jens wondered about the ramifications of supporting Unicode scalar
          values as opposed to assigned characters and when character
          properties become relevant; the Unicode of 1993 differs substantially
          from Unicode today.</li>
      <li>Martinho noted that Unicode has not always maintained backwards
          compatibility.</li>
      <li>Hubert agreed and noted that the Unicode code space shrunk in Unicode
          2.0 when UTF-16 and surrogate code points were defined.  </li>
      <li>Jens observed that UCNs can be explicitly written to produce arbitrary
          scalar values, including scalar values corresponding to unassigned
          code points.</li>
      <li>PBrett responded that explicit UCNs are rarely seen outside of
          compiler test suites.</li>
      <li>PBrett added that, conceptually, post translation phase 1, only scalar
          values remain.</li>
      <li>Jens expressed uncertainty; that it isn't clear that newly assigned
          Unicode characters have meaning for an existing C++ standard.</li>
      <li>PBrett responded that such meaning is immaterial since explicit UCNs
          are allowed to name unassigned code points.</li>
      <li>Jens acknowledged that we have to define behavior for all possible
          Unicode scalar values whether assigned or not.</li>
      <li>PBrett agreed and noted that such behavior impacts the set of allowed
          identifiers as proposed in
          <a href="https://wg21.link/p1949">P1949: C++ Identifier Syntax using Unicode Standard Annex 31</a>.</li>
      <li>Jens wondered if character properties are actually relevant for
          translation phase 1.</li>
      <li>Hubert stated that it is important to understand whether there would
          be a benefit to insisting that code points correspond to assigned
          characters in particular contexts.</li>
      <li>Hubert added that stating that lexing and parsing are in terms of
          assigned characters would be distracting in general.</li>
      <li>Martinho returned discussion to the example Jens provided of an
          implementation being behind the current Unicode standard; there are
          motivating use cases for use of a UCN for a code point that has not
          yet been assigned by Unicode in a published standard.  For example,
          in anticipation of a new Japanese calendar era,
          U+32FF (SQUARE ERA NAME REIWA) was reserved before the new era began
          though the new character did not appear in a published Unicode
          standard until after the era began.</li>
      <li>Corentin noted that there is no intent to remove support for explicit
          UCNs.</li>
      <li>Corentin aded that, whether a code point is assigned or not only
          matters during translation phase 1 conversions.</li>
      <li>Hubert asserted that it would be undesirable to specify constraints
          on translation phase 1 conversions; some implementations use
          <tt>iconv</tt>, implementors may not want to validate <tt>iconv</tt>
          and instead document their implementation-defined behavior as,
          "whatever <tt>iconv</tt> does".</li>
      <li>Corentin stated that there is no intent to restrict
          implementation-defined character mapping in translation phase 1.</li>
      <li>PBrett responded that, in principle, requiring Unicode characters
          post translation phase 1 would require rejecting Unicode scalar values
          corresponding to unassigned code points.</li>
      <li>Jens reflected on earlier terminology discussions and joking about
          what "character" means because it is hazy and strange.</li>
      <li>Jens opined that, unless "character" is defined in such a way that
          any benefits it offers over "scalar value" are made apparent, we
          should avoid it.</li>
      <li>PBrett disagreed.</li>
      <li>Jens noted that the telecon was about to end and stated that it may
          be useful to expand on that at a future telecon.</li>
      <li>PBrett asked if more time should be dedicated to this topic.</li>
      <li>Tom expressed support for more time as different perspectives suggest
          we would benefit from increasing understanding.</li>
      <li>Hubert noted that there will be a competing paper partially motivated
          by a desire for the standard to remain abstract and not tied too
          heavily to Unicode.</li>
      <li>Corentin expressed little interest in the distinction between
          characters and scalar values; that character properties are what
          matters.</li>
      <li>Corentin added that LEWG will be backed up in C++23, so it is good to
          focus on these core language issues now.</li>
      <li>Mark agreed; this is fundamental work.</li>
    </ul>
  </li>
  <li>Tom stated that the next meeting will be in three weeks, on October 14th,
      and that we'll probably start discussion with a review of recent updates
      to
      <a href="https://github.com/tzlaine/text">Boost.Text</a>,
      and then continue discussion of this paper.</li>
</ul>


</body>
